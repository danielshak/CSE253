{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#Misc imports\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to convert string to one hot encoding\n",
    "def to_onehot(data):\n",
    "    ascii_list = []\n",
    "    elements_per_song = []\n",
    "    for songs in data:\n",
    "        elements_per_song.append(len(songs))\n",
    "        for chars in songs:\n",
    "            ascii_list.append(ord(chars))\n",
    "    onehot_vals = np.eye(128)[ascii_list]\n",
    "    return onehot_vals, np.array(ascii_list), np.array(elements_per_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data is a list of list of chars, each string list is a song\n",
    "#onehot_ascii output are shifted up by 1, need to figure out what to do with 0 array labels\n",
    "def onehot_songs(data, sequence_length):\n",
    "    max_num_chars = 0\n",
    "    temp_list = []\n",
    "    onehot_ascii = []\n",
    "    onehot_songs = []\n",
    "    \n",
    "    #List of songs in ascii format\n",
    "    for song in data:\n",
    "        if len(song)>max_num_chars:\n",
    "            max_num_chars = len(song) #Finds longest song length\n",
    "        for chars in song:\n",
    "            temp_list.append(ord(chars))\n",
    "        onehot_ascii.append(temp_list)\n",
    "        temp_list = []\n",
    "        \n",
    "    #To make divisible by sequence_length per batch\n",
    "    max_num_chars = sequence_length-(max_num_chars%sequence_length)+max_num_chars\n",
    "    codding = np.append(np.zeros((1,128)),np.eye(128),0)    \n",
    "    \n",
    "    for i, ascii_song in enumerate(onehot_ascii):\n",
    "        ascii_song = np.array(ascii_song)+1 #since making first row of eye matrix all 0s\n",
    "        needed_0s = max_num_chars-len(ascii_song)\n",
    "        onehot_ascii[i] = np.pad(ascii_song,(0,needed_0s),'constant',constant_values=0)\n",
    "        onehot_songs.append(codding[onehot_ascii[i]])\n",
    "        \n",
    "    return onehot_ascii, onehot_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data is onehot array of every char in train\n",
    "#labels are every ascii value of every char in train\n",
    "def make_sequence(data,labels,sequence_length):\n",
    "    num_groups = np.floor(len(labels)/sequence_length) #length labels same as data\n",
    "    remainder = len(labels)%sequence_length\n",
    "    #Add 1 here to grab one time step ahead for predicting labels\n",
    "    label_groups = np.split(labels[0+1:len(labels)-remainder+1],num_groups)\n",
    "    onehot_groups = np.vsplit(data[0:len(labels)-remainder],num_groups)\n",
    "    return np.array(onehot_groups),np.array(label_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size is the number of sequences per batch\n",
    "def batching(onehot_data,labels,batch_size):\n",
    "    num_batches = np.floor(len(labels)/batch_size)\n",
    "    num_subtract = len(labels)%batch_size\n",
    "    label_batches = np.vsplit(labels[0:len(labels)-num_subtract],num_batches)\n",
    "    onehot_batches = np.split(onehot_data[0:len(labels)-num_subtract],num_batches,0)\n",
    "    return np.array(onehot_batches),np.array(label_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Class LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_rnn(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_layers=1,batch_size=1,\n",
    "                 sequence_length=25,batch_first = True):\n",
    "        super(lstm_rnn, self).__init__()\n",
    "        #Constants\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        #Initializing model\n",
    "        self.lstm = nn.LSTM(input_size,hidden_size,num_layers,batch_first = batch_first)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.input_size)\n",
    "        \n",
    "    def forward(self,data,initial):\n",
    "        #data = data.view(self.batch_size, self.sequence_length, self.input_size)\n",
    "        output,hidden = self.lstm(data,initial)\n",
    "        out = self.fc(output.contiguous().view(-1,output.size(2)))\n",
    "        print(out.shape)\n",
    "        out = F.softmax(output)\n",
    "        return out,hidden\n",
    "        \n",
    "    def init_hidden(self,zero=1):\n",
    "        if zero == 0:\n",
    "            #Random initialization\n",
    "            initial_hidden = autograd.Variable(torch.randn(self.num_layers,self.batch_size,self.hidden_size))\n",
    "        else:\n",
    "            #Zero initialization\n",
    "            initial_hidden = autograd.Variable(torch.zeros(self.num_layers,self.batch_size,self.hidden_size))\n",
    "        return initial_hidden\n",
    "    \n",
    "    def init_cell(self,zero=1):\n",
    "        if zero == 0:\n",
    "            #Random initialization\n",
    "            initial_cell = autograd.Variable(torch.randn(self.num_layers,self.batch_size,self.hidden_size))\n",
    "        else:\n",
    "            #Zero initialization\n",
    "            initial_cell = autograd.Variable(torch.zeros(self.num_layers,self.batch_size,self.hidden_size))\n",
    "        return initial_cell\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./Data/input.txt\")\n",
    "text = file.readlines()\n",
    "file.close()\n",
    "\n",
    "text_array = np.asarray(text)\n",
    "\n",
    "#Creates list of each song\n",
    "indicies = np.where(text_array == '<start>\\n') #Location of where each abc file starts\n",
    "data = []\n",
    "for i in range(len(indicies[0])):\n",
    "    if i+1 == len(indicies[0]):\n",
    "        #For the last abc file\n",
    "        abc = text_array[indicies[0][i]:]\n",
    "    else:\n",
    "        abc = text_array[indicies[0][i]:indicies[0][i+1]]\n",
    "    data.append(''.join(abc))\n",
    "\n",
    "#print(data[0])\n",
    "#print(data[1123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#80 - 20 split on data -> training and validation\n",
    "#Constants\n",
    "train_len = int(np.floor(len(data)*0.8))\n",
    "validation_len = len(data) - train_len\n",
    "\n",
    "np.random.seed(0)\n",
    "#Each index references to a single song\n",
    "indxs = np.asarray(range(len(data)))\n",
    "np.random.shuffle(indxs)\n",
    "\n",
    "train_data = (np.asarray(data))[indxs[0:train_len]]\n",
    "validation_data = (np.asarray(data))[indxs[train_len:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Data and LSTM constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM constants\n",
    "input_size = 128 #num_classes = 128\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "batch_first = True\n",
    "batch_size = 500\n",
    "sequence_length = 25\n",
    "\n",
    "#Data\n",
    "#combines all the songs and makes a single string, converted to ascii and onehot\n",
    "onehot_train_full, train_labels_full, train_NumPerSong = to_onehot(train_data)\n",
    "onehot_validation_full, validation_labels_full, validation_NumPerSong = to_onehot(validation_data)\n",
    "#print(train_labels[0])\n",
    "#print(onehot_train[0])\n",
    "\n",
    "#or using onehot song encoddings\n",
    "#onehot_train, train_labels_padded = onehot_songs(train_data,sequence_length)\n",
    "#onehot_validation, validation_labels_padded = onehot_songs(validation_data,sequence_length)\n",
    "\n",
    "#divide data based on sequence length\n",
    "onehot_train, train_labels = make_sequence(onehot_train_full,\n",
    "                                           train_labels_full,\n",
    "                                           sequence_length)\n",
    "\n",
    "onehot_validation, validation_labels = make_sequence(onehot_validation_full,\n",
    "                                                     validation_labels_full,\n",
    "                                                     sequence_length)\n",
    "\n",
    "#Makes batches, labels are 1 time step ahead for predicting outputs\n",
    "onehot_batches,batch_labels = batching(onehot_train,train_labels,batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run first in single batches, each batch has 25 chars per(sequence length 25), just run it in order of the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feature size:  128\n",
      "Number of hidden LSTM units:  128\n",
      "Batch Size:  500\n",
      "Elements per sequence:  25\n",
      "Number of LSTM layers:  1\n",
      "\n",
      " lstm_rnn(\n",
      "  (lstm): LSTM(128, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=128)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lstm = lstm_rnn(input_size,hidden_size,num_layers,batch_size,\n",
    "                sequence_length,batch_first = batch_first)\n",
    "lstm.cuda()\n",
    "\n",
    "print(\"Input feature size: \", lstm.input_size)\n",
    "print(\"Number of hidden LSTM units: \", lstm.hidden_size)\n",
    "print(\"Batch Size: \", lstm.batch_size)\n",
    "print(\"Elements per sequence: \", lstm.sequence_length)\n",
    "print(\"Number of LSTM layers: \", lstm.num_layers)\n",
    "print(\"\\n\",lstm)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(lstm.parameters(), lr=0.1)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2 or 4 dimensions (got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e4392278a47f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#output = output.contiguous().view(-1,output.size(2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#if using linear layer, output should be shaped correctly already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloss_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         return F.cross_entropy(input, target, self.weight, self.size_average,\n\u001b[0;32m--> 601\u001b[0;31m                                self.ignore_index, self.reduce)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \"\"\"\n\u001b[0;32m-> 1140\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected 2 or 4 dimensions (got {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2 or 4 dimensions (got 3)"
     ]
    }
   ],
   "source": [
    "#Initialize hidden states\n",
    "h_0 = lstm.init_hidden().cuda()\n",
    "c_0 = lstm.init_cell().cuda()\n",
    "states = (h_0,c_0)\n",
    "loss = []\n",
    "accuracy = []\n",
    "num_batches = len(onehot_batches) #when using 500 per batch, results in 32 total batches\n",
    "    \n",
    "for epoch in range(5):\n",
    "    for indx in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "        in_data = autograd.Variable(torch.FloatTensor(onehot_batches[indx])).cuda()\n",
    "        output,states = lstm(in_data,states)\n",
    "        \n",
    "        h_0 = autograd.Variable(states[0].data, requires_grad=True).cuda()\n",
    "        c_0 = autograd.Variable(states[1].data, requires_grad=True).cuda()\n",
    "        states = (h_0,c_0)\n",
    "        \n",
    "        #Labels are 1 time step ahead in time\n",
    "        #500 by 25 per batch\n",
    "        labels = batch_labels[indx].reshape(batch_size*sequence_length)\n",
    "        labels = autograd.Variable(torch.LongTensor(labels)).cuda() \n",
    "                            \n",
    "        #pretty sure that loss function will average over number of inputs\n",
    "        #if not using linear layer\n",
    "        #output = output.contiguous().view(-1,output.size(2))\n",
    "        #if using linear layer, output should be shaped correctly already\n",
    "        loss_temp = criterion(output,labels)\n",
    "        loss.append(loss_temp.data)\n",
    "        loss_temp.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #vals,max_indxs = (output.data).max(2)\n",
    "        #acc_temp = (max_indxs==(labels.data)).sum()\n",
    "        #accuracy.append(acc_temp/sequence_length)\n",
    "        #print(loss)\n",
    "        #print(accuracy)\n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a function for this later \n",
    "primer = \"<start>\\n\"\n",
    "start_token = []\n",
    "for chars in primer:\n",
    "    start_token.append(ord(chars))\n",
    "    \n",
    "start_token = np.eye(128)[start_token]\n",
    "start_token = torch.from_numpy(start_token).float()\n",
    "start_token = autograd.Variable(start_token.view(1,8,input_size))\n",
    "#print(start_token.argmax(1))\n",
    "\n",
    "end = \"<end>\"\n",
    "end_token = []\n",
    "for chars in end:\n",
    "    end_token.append(ord(chars))\n",
    "    \n",
    "end_token = np.eye(128)[end_token]\n",
    "\n",
    "done = 1\n",
    "\n",
    "#Generating music\n",
    "h_0 = lstm.init_hidden()\n",
    "c_0 = lstm.init_cell()\n",
    "states = (h_0,c_0)\n",
    "chars = []\n",
    "\n",
    "#Each loop generates 1 char\n",
    "for i in range(100):\n",
    "    output,states = lstm(start_token,states)\n",
    "    \n",
    "    h_0 = autograd.Variable(states[0].data, requires_grad=True)\n",
    "    c_0 = autograd.Variable(states[1].data, requires_grad=True)\n",
    "    states = (h_0,c_0)\n",
    "    \n",
    "    #Currently I am taking the max of the hidden state as the letter that it\n",
    "    #produces, the TA on piazza said that it is not ideal to take max,\n",
    "    #can try implementing what he says later\n",
    "    val,indx = states[0].data.max(2)\n",
    "    chars.append(indx)\n",
    "    \n",
    "    start_token = torch.from_numpy(np.eye(128)[indx]).float()\n",
    "    start_token = autograd.Variable(start_token.view(1,1,input_size))\n",
    "    \n",
    "    #Need to implement a check for \"<end>\", generation should stop once\n",
    "    #\"<end>\" is produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting back to strings\n",
    "outputs = []\n",
    "for letter in chars:\n",
    "    outputs.append(chr(letter))\n",
    "\n",
    "print(chars)\n",
    "print(outputs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
